{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chess Engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "mount_file_id": "1T47A2Zv9HXd3II1xqbGDeXMF9EL95V7S",
      "authorship_tag": "ABX9TyPWsZNI4hl0e8PZQAl5F7ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GOTWIC/AI-Chess-Engine/blob/main/Chess_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "gyjjMy5FPpgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-i4Nh7rLVXf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import gc\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Original Dataset and Reformat to Custom Dataframe (Not Recommended)\n",
        "\n",
        "The steps in this section achieve the following:\n",
        "1. Import the Original Kaggle dataset\n",
        "2. Load the Dataset into a dataframe\n",
        "3. Parse and Reformat the dataframe for all 13 million positions into a new dataframe\n",
        "4. Upload new dataframe to Google Drive as a .CSV file.\n",
        "\n",
        "Because reformatting 13 million chess positions is incredibly resource intensive, it's better to download the reformatted .CSV file that is generated at the end of this process. Using the reformatted .CSV file will significantly reduce the setup time for subsequent sessions.\n",
        "\n",
        "\n",
        "\n",
        "### *If you want to download the reformatted .CSV file:*\n",
        "*It is better to save the reformatted file to drive and download from there (10 minutes total), rather than save the file to colab's local storage and download directly from here (20 minutes or more).*"
      ],
      "metadata": {
        "id": "3r4owU88OFv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dataset \n",
        "\n",
        "1.   Download Kaggle API .json file\n",
        "2.   Upload to Google Drive (root folder)\n",
        "3.   Mount Google Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "Jg4qYtA3Ps89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download ronakbadhe/chess-evaluations\n",
        "! unzip chess-evaluations.zip"
      ],
      "metadata": {
        "id": "SSraT30nL8Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Read Dataset"
      ],
      "metadata": {
        "id": "2QCxH1G4Q1n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'chessData.csv' \n",
        "rawData = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "J0HX3XHhMg-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse FEN + Evaluation into Custom Data Frame\n",
        "\n",
        "The original data frame includes only two columns: the FEN and the Evaluation. To prepare the dataset for inputting, we need to reformat the input. The reformatting parses the FEN string and allocates a column for every square on the board (64 squares), and an additional column for the evaluation (65 columns in total).\n",
        "\n",
        "***This step will take around 18 minutes to complete.***"
      ],
      "metadata": {
        "id": "xzrTh3fleRHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parsePiece(piece):\n",
        "  return {\n",
        "        'P': 1,\n",
        "        'N': 2,\n",
        "        'B': 3,\n",
        "        'R': 4,\n",
        "        'Q': 5,\n",
        "        'K': 6,\n",
        "        'p': -1,\n",
        "        'n': -2,\n",
        "        'b': -3,\n",
        "        'r': -4,\n",
        "        'q': -5,\n",
        "        'k': -6,\n",
        "    }[piece]\n",
        "\n",
        "rows = len(rawData)\n",
        "rawParse = np.empty([rows, 65])\n",
        "\n",
        "for row in range(rows):\n",
        "  FENIndex = 0\n",
        "  for char in rawData.FEN[row]:\n",
        "    if char.isalpha():\n",
        "      rawParse[row][FENIndex] = parsePiece(char)\n",
        "      FENIndex += 1\n",
        "    elif char.isdigit():\n",
        "      for emptySpace in range(int(char)):\n",
        "        rawParse[row][FENIndex] = 0\n",
        "        FENIndex += 1\n",
        "    elif char == ' ':\n",
        "      break\n",
        "\n",
        "  eval = rawData.Evaluation[row]\n",
        "  if eval[0] == '+':\n",
        "    rawParse[row][64] = int(eval[1:])\n",
        "  elif eval[0] == '-':\n",
        "    rawParse[row][64] = -1 * int(eval[1:])\n",
        "  elif eval[0] == '#':\n",
        "    if eval[1] == '+':\n",
        "      rawParse[row][64] = 32000\n",
        "    elif eval[1] == '-':\n",
        "      rawParse[row][64] = -32000\n",
        "  else:\n",
        "    rawParse[row][64] = 0\n",
        "\n",
        "  if row%100000 == 0:\n",
        "    print(\"Currently reformatting position #\" + str(row))\n",
        "\n",
        "print(\"Finished processing \" + str(rows) + \" positions\")\n",
        "  \n",
        "\n",
        "squareLabels = []\n",
        "for i in range(1, 9):\n",
        "  for j in range(1, 9):\n",
        "    squareLabels.append(chr(j + 96) + chr((8-i) + 49))\n",
        "squareLabels.append('Evaluation')\n",
        "\n",
        "data = pd.DataFrame(rawParse, columns = squareLabels)\n",
        "downcasted_data = data.apply(pd.to_numeric,downcast='signed')\n",
        "\n",
        "print(\"Reformatting Complete\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GT7LZfg7OJq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete the Original Dataframe\n",
        "Reformatting pretty much deletes all of your ram. This step will free up some memory space."
      ],
      "metadata": {
        "id": "TkvAoCP8P-nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del rawData\n",
        "del data\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Mkim-ATqCge0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save New Dataframe as a .CSV file and download to Google Drive\n",
        "After this step, you can import the new dataframe directly from Google Drive."
      ],
      "metadata": {
        "id": "Iit-wR7cPqj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/ReformattedChessDataset.csv'\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  downcasted_data.to_csv(f)"
      ],
      "metadata": {
        "id": "Zh7n0j7mLYjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Reformatted Dataset"
      ],
      "metadata": {
        "id": "nGtWLEgHSSvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download swagnikroychoudhury/reformattedchessdataset\n",
        "! unzip reformattedchessdataset.zip"
      ],
      "metadata": {
        "id": "t409A9g3A8hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'reformattedChessData.csv' \n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "U6kb3UuvBi1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info(memory_usage='deep')\n"
      ],
      "metadata": {
        "id": "wax4yaZvEPYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mem_usage(pandas_obj):\n",
        "    if isinstance(pandas_obj,pd.DataFrame):\n",
        "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
        "    else: # we assume if not a df it's a series\n",
        "        usage_b = pandas_obj.memory_usage(deep=True)\n",
        "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
        "    return \"{:03.2f} MB\".format(usage_mb)\n",
        "\n",
        "print(data)\n",
        "\n",
        "downcasted_data = data.apply(pd.to_numeric,downcast='signed')\n",
        "\n",
        "print(downcasted_data)\n",
        "\n",
        "row2cast = data.loc[1]\n",
        "row2cast3 = row2cast.select_dtypes(include=['float64'])\n",
        "row2cast2 = row2cast3.apply(pd.to_numeric,downcast='signed')\n",
        "print(row2cast)\n",
        "print(row2cast2)\n",
        "\n",
        "#gl_int = data.select_dtypes(include=['float64'])\n",
        "#print(gl_int)\n",
        "#dowcasted_data = data.apply(pd.to_numeric,downcast='signed')\n",
        "#print(converted_int)\n",
        "\n",
        "\n",
        "#print(mem_usage(gl_int))\n",
        "#print(mem_usage(converted_int))\n",
        "\n",
        "#converted_int.info(memory_usage='deep')"
      ],
      "metadata": {
        "id": "NTkGdFi9GQBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FK8Nvm2PH30K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}